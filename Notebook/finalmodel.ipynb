{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>past_topic</th>\n",
       "      <th>future_topic</th>\n",
       "      <th>past_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3, 0, 3, 20, 69, 69, 36, 22]</td>\n",
       "      <td>[32, 44, 0]</td>\n",
       "      <td>[[564180], [3405, 192788], [597499], [1101544]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[47, 46, 7]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[[2076127], [2022749], [799008]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[44, 0, 0, 44]</td>\n",
       "      <td>[0, 4, 0]</td>\n",
       "      <td>[[1931814], [354601, 477767, 477399, 472684, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[39, 61, 3, 0, 16, 0, 3, 31, 45, 24]</td>\n",
       "      <td>[3, 0, 45]</td>\n",
       "      <td>[[1659033, 1643460, 1640173], [2298131], [5809...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[7, 50, 34, 28, 0, 15, 25]</td>\n",
       "      <td>[46, 6, 8]</td>\n",
       "      <td>[[790864], [2092319], [1464056, 1457409, 14467...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             past_topic future_topic  \\\n",
       "0         [3, 0, 3, 20, 69, 69, 36, 22]  [32, 44, 0]   \n",
       "1                           [47, 46, 7]    [0, 0, 0]   \n",
       "2                        [44, 0, 0, 44]    [0, 4, 0]   \n",
       "3  [39, 61, 3, 0, 16, 0, 3, 31, 45, 24]   [3, 0, 45]   \n",
       "4            [7, 50, 34, 28, 0, 15, 25]   [46, 6, 8]   \n",
       "\n",
       "                                           past_leaf  \n",
       "0  [[564180], [3405, 192788], [597499], [1101544]...  \n",
       "1                   [[2076127], [2022749], [799008]]  \n",
       "2  [[1931814], [354601, 477767, 477399, 472684, 4...  \n",
       "3  [[1659033, 1643460, 1640173], [2298131], [5809...  \n",
       "4  [[790864], [2092319], [1464056, 1457409, 14467...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('tmall.pickle')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('topic_items_to_emb-tmall.pkl','rb') as fp:\n",
    "    embedding_map = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_negative.pkl','rb') as fp:\n",
    "    training_negative = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41711/41711 [01:02<00:00, 669.62it/s] \n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "all_zero = [0 for _ in range(256)]\n",
    "for i in tqdm(range(int(len(df)*0.1))):\n",
    "    row = df.iloc[i]\n",
    "    past_id = row['past_topic']\n",
    "    gt = row['future_topic']\n",
    "    leaves = []\n",
    "    for j in range(len(past_id)):\n",
    "        key = tuple((past_id[j],tuple(row['past_leaf'][j])))\n",
    "        leaves += list(embedding_map[key])\n",
    "    \n",
    "    for _ in range(10 - len(past_id)):\n",
    "        leaves += all_zero\n",
    "        \n",
    "    temp = [72 for _ in range(10-len(past_id))]\n",
    "    xs = []\n",
    "    xs += past_id\n",
    "    xs += temp\n",
    "    xs += leaves\n",
    "    candidate = list(copy(training_negative[i]))\n",
    "    candidate += past_id\n",
    "    for each in set(candidate):\n",
    "        temp = copy(xs)\n",
    "        temp.insert(11,each)\n",
    "        x.append(temp)\n",
    "        if each in gt:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x,dtype=torch.float)\n",
    "y = torch.tensor(y,dtype=torch.float)\n",
    "x = x.to('cuda:0')\n",
    "y = y.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'embedding_dim': 64,\n",
    "    'num_cate': 72,\n",
    "    'vae' : 256,\n",
    "    'dim1' : 1024,\n",
    "    'dim2' : 256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class user_preference_estimator(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(user_preference_estimator, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = config['embedding_dim']\n",
    "        self.num_cateogry = config['num_cate'] + 1\n",
    "        self.vae = config['vae']\n",
    "        self.fc1_in_dim = config['embedding_dim']  * 10 * 2 + config['embedding_dim']\n",
    "        self.fc2_in_dim = config['dim1']\n",
    "        self.fc2_out_dim = config['dim2']\n",
    "\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.num_cateogry,self.embedding_dim)\n",
    "        self.vaeencoder = torch.nn.Linear(self.vae,self.embedding_dim)\n",
    "        self.fc1 = torch.nn.Linear(self.fc1_in_dim, self.fc2_in_dim)\n",
    "        self.fc2 = torch.nn.Linear(self.fc2_in_dim, self.fc2_out_dim)\n",
    "        self.linear_out = torch.nn.Linear(self.fc2_out_dim, 1)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #First ten entries are categories\n",
    "        category = Variable(x[:, 0:11], requires_grad=False)\n",
    "        leaf = Variable(x[:,11:], requires_grad=False)\n",
    "        leaf = leaf.view(-1,10,self.vae)\n",
    "        out = self.embedding(category.long())\n",
    "        out = out.view(-1,self.embedding_dim*11)\n",
    "        out2 = self.vaeencoder(leaf)\n",
    "        out2 = out2.view(-1,self.embedding_dim*10)\n",
    "        out = torch.cat((out, out2), 1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.linear_out(out)\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_preference_estimator(\n",
       "  (embedding): Embedding(73, 64)\n",
       "  (vaeencoder): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc1): Linear(in_features=1344, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (linear_out): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = user_preference_estimator(config)\n",
    "estimator.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qwang65/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 553572/553572 [38:53<00:00, 237.27it/s]\n",
      "  0%|          | 1029/553572 [00:04<42:36, 216.17it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mlosses_q\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclamp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     losses_q\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/fx/traceback.py:68\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/usr/lib/python3.8/traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 211\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m/usr/lib/python3.8/traceback.py:362\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    359\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[1;32m    360\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[0;32m--> 362\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[0;32m/usr/lib/python3.8/linecache.py:74\u001b[0m, in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(estimator.parameters(), lr = 0.001)\n",
    "for _ in range(5):\n",
    "    for i in tqdm(range(len(x))):\n",
    "        losses_q = []\n",
    "        y_pred = estimator.forward(x[i:i+1])\n",
    "        loss_q = F.mse_loss(y_pred, y[i:i+1].view(-1, 1))\n",
    "        losses_q.append(loss_q)\n",
    "        losses_q = torch.stack(losses_q).mean(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.autograd.set_detect_anomaly(True):\n",
    "            losses_q.clamp(min=1e-6)\n",
    "            losses_q.backward()\n",
    "        optimizer.step()\n",
    "    torch.save(estimator.state_dict(),\"final.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testing_negative.pkl','rb') as fp:\n",
    "    testing_negative = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4171/4171 [00:02<00:00, 1737.18it/s]\n"
     ]
    }
   ],
   "source": [
    "xt = []\n",
    "yt = []\n",
    "all_zero = [0 for _ in range(256)]\n",
    "cand = []\n",
    "offset = int(len(df)*0.9)\n",
    "for i in tqdm(range(int(len(df)*0.9),int(0.91*len(df)))):\n",
    "    row = df.iloc[i]\n",
    "    past_id = row['past_topic']\n",
    "    gt = row['future_topic']\n",
    "    leaves = []\n",
    "    for j in range(len(past_id)):\n",
    "        key = tuple((past_id[j],tuple(row['past_leaf'][j])))\n",
    "        leaves += list(embedding_map[key])\n",
    "    \n",
    "    for _ in range(10 - len(past_id)):\n",
    "        leaves += all_zero\n",
    "        \n",
    "    temp = [72 for _ in range(10-len(past_id))]\n",
    "    xs = []\n",
    "    xs += past_id\n",
    "    xs += temp\n",
    "    xs += leaves\n",
    "    candidate = list(copy(testing_negative[i-offset]))\n",
    "    candidate += past_id\n",
    "    candidate = list(set(candidate))\n",
    "    cx = []\n",
    "    for each in candidate:\n",
    "        temp = copy(xs)\n",
    "        temp.insert(11,each)\n",
    "        cx.append(temp)\n",
    "    xt.append(cx)\n",
    "    yt.append(gt)\n",
    "    cand.append(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeScore(ret,gt,t,show=True):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    h = 0\n",
    "    for i in range(len(ret)):\n",
    "        ht = 0\n",
    "        for each in ret[i][0:t]:\n",
    "            if each in gt[i]:\n",
    "                tp += 1\n",
    "                ht = 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        for each in gt[i]:\n",
    "            if each not in ret[i]:\n",
    "                fn += 1\n",
    "        h += ht\n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "    f = 2*p*r/(p+r)\n",
    "    if show:\n",
    "        print(\"HR@\" + str(t) + \"       :\" + str(h/len(ret)))\n",
    "        print(\"Precision@\" + str(t) + \":\" + str(p))\n",
    "        print(\"Recall@\" + str(t) + \"   :\" + str(r))\n",
    "        print(\"F1@\" + str(t) + \"       :\" + str(f))\n",
    "        print(\"*************************************************************\")\n",
    "    return h/len(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(m,x,gt,cand):\n",
    "    ret = []\n",
    "    for i in tqdm(range(len(x))):\n",
    "        xc = x[i]\n",
    "        xc = torch.tensor(xc,dtype=torch.float)\n",
    "        out = m(xc)\n",
    "        out = out.detach().numpy().flatten()\n",
    "        sorting = np.argsort(-1 * out)\n",
    "        temp = []\n",
    "        for each in sorting:\n",
    "            temp.append(cand[i][each])\n",
    "        ret.append(temp)\n",
    "    for t in [1,3,5,7,10]:\n",
    "        ComputeScore(ret,gt,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4171 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4171/4171 [00:15<00:00, 263.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@1       :0.2155358427235675\n",
      "Precision@1:0.2155358427235675\n",
      "Recall@1   :0.15686616646309545\n",
      "F1@1       :0.18157947889315287\n",
      "*************************************************************\n",
      "HR@3       :0.40517861424118917\n",
      "Precision@3:0.14544873331734995\n",
      "Recall@3   :0.2736019242333133\n",
      "F1@3       :0.18992955909209494\n",
      "*************************************************************\n",
      "HR@5       :0.635578997842244\n",
      "Precision@5:0.15823543514744665\n",
      "Recall@5   :0.4058042302016724\n",
      "F1@5       :0.2276882740538862\n",
      "*************************************************************\n",
      "HR@7       :0.8010069527691202\n",
      "Precision@7:0.16566770558619037\n",
      "Recall@7   :0.5002585582790361\n",
      "F1@7       :0.24890649925384659\n",
      "*************************************************************\n",
      "HR@10       :0.888995444737473\n",
      "Precision@10:0.14799808199472547\n",
      "Recall@10   :0.5609268514311676\n",
      "F1@10       :0.23420278858010052\n",
      "*************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = user_preference_estimator(config)\n",
    "model.load_state_dict(torch.load(\"final.pkl\"))\n",
    "TestModel(model,xt,yt,cand)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
